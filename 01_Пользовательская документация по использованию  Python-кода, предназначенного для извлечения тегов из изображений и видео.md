### Введение
Этот документ предоставляет обзор Python-кода, предназначенного для извлечения тегов из изображений и видео. Код использует YOLOv8 для обнаружения объектов и трансформеры для классификации изображений методом ZeroShot Classification. Функциональность включает в себя загрузку моделей, обработку изображений и видео, а также извлечение соответствующих тегов.

### 1. Требования 

- Python 3.x
- Основные необходимые библиотеки Python: 
	- [ultralytics](https://github.com/ultralytics/yolov5): библиотека для работы с YOLOv8.
	- [transformers](https://huggingface.co/transformers/): библиотека для работы с предобученными моделями, в данном случае, с трансформерами.
	- [torch](https://pytorch.org/): фреймворк для глубокого обучения.
	- [PIL](https://pillow.readthedocs.io/): библиотека для работы с изображениями.
	- [numpy](https://numpy.org/): библиотека для операций с массивами и матрицами.
	- [matplotlib](https://matplotlib.org/): библиотека для создания графиков и визуализации данных.
	- [pathlib](https://docs.python.org/3/library/pathlib.html): библиотека для работы с путями к файлам и директориям.
	- [fleep](https://pypi.org/project/fleep/): библиотека для определения типа файла по его содержимому.
	- [cv2](https://opencv.org/): библиотека для компьютерного зрения.
	- [moviepy](https://zulko.github.io/moviepy/): библиотека для обработки видеофайлов.
	- [openpyxl](https://openpyxl.readthedocs.io/): библиотека для работы с файлами Excel.
	
- Полный перечень необходимых библиотек и модулей предоставлен в файле `requirements.txt` 

### 2. Настройка
Перед запуском кода убедитесь, что необходимые библиотеки Python установлены. 
Все необходимые библиотеки и модули представлены в файле requirements.txt
#### Установка зависимостей из `requirements.txt`
Вы можете использовать утилиту `pip` для установки зависимостей из файла `requirements.txt`. Откройте терминал или командную строку и выполните следующую команду в директории вашего проекта:

```bash
pip install -r requirements.txt
```

Эта команда прочитает файл `requirements.txt` и установит все зависимости в соответствии с указанными версиями.

### 3. Основные функции и переменные

#### 3.1. Функции для загрузки моделей и библиотек

##### 3.1.1. Загрузка YOLOv8 Модели
Загрузка модели YOLOv8 выполняется с помощью функции`load_model_yolo(yolo_path)`, чтобы получить объект модели, который затем может быть использован в других частях кода для выполнения обнаружения объектов на изображениях или видео.
```python
model_yolo = load_model_yolo(yolo_path)
```
- **Описание**: Функция загружает модель YOLOv8 с дообученными весами.
- **Параметры**: `yolo_path`: путь к сохраненным весам модели YOLOv8 обученных на датасете пользователя. 
- **Возвращаемое значение**: - `model_saved`: Загруженная модель YOLOv8.

##### 3.1.2. Загрузка Модели transformers/pipeline для ZeroShot Classification
Функция `load_pipeline` предоставляет удобный способ загрузить pipeline для модели, предназначенной для ZeroShot Classification. Вы можете использовать полученный pipeline для классификации текста с использованием различных меток без предварительного обучения модели на конкретных классах.

- **Описание**: Загружает и возвращает pipeline для модели transformers, предназначенной для выполнения задачи ZeroShot Classification.
- **Параметры**: 
    - `model_name (str)`: Имя модели, которую вы хотите загрузить. Это может быть название предварительно обученной модели, которая поддерживает ZeroShot Classification. Перечень моделей доступен по ссылке: https://huggingface.co/models?pipeline_tag=zero-shot-image-classification
    - `task (str, optional)`: Задача, для которой предназначена модель. Значение по умолчанию: None.
    - `device_gpu (int, optional)`: Устройство, на котором будет выполняться модель. Если у вас есть GPU и вы хотите использовать его, укажите 0. Значение по умолчанию: None.
- **Возвращаемое значение**:
    - `pipe:` Загруженный pipeline для модели ZeroShot Classification.

> [!NOTE] **Пример использования:** 
> ```python
> zero_shot_classifier = load_pipeline(model_name='openai/clip-vit-large-patch14', device_gpu=0)
> ```
> 

##### 3.1.3. Загрузка Модели transformers/pipeline для Image-to-Text 
Функция `load_pipeline_des` позволяет легко загрузить pipeline для модели, предназначенной для преобразования изображений в текст. После загрузки pipeline, вы можете использовать его для генерации текстовых описаний на основе входных изображений.

**Описание:** Загружает и возвращает pipeline для модели transformers предназначенной для преобразования изображений в текст (Image-to-Text). 
- Параметры: 
	- `model_name (str)`: Имя модели, которую вы хотите загрузить. Это может быть название предварительно обученной модели, которая поддерживает Image-to-Text задачу. 
	- `task (str, optional)`: Задача, для которой предназначена модель. Значение по умолчанию: None. 
	- `device_gpu (int, optional)`: Устройство, на котором будет выполняться модель. Если у вас есть GPU и вы хотите использовать его, укажите 0. Значение по умолчанию: None.
- Возвращаемое значение: - pipe: Загруженный pipeline для модели Image-to-Text. 

> [!NOTE] Пример использования:
> 
> ```python
> image_to_text_pipeline = load_pipeline_des(model_name='Salesforce/blip-image-captioning-large', device_gpu=0)

#### 3.2. Функции для извлечения тегов из изображения и видео

##### 3.2.1. Извлечение тегов из изображения
```python
image_tags = tags_extraction_complex(source_path=image_path,
                                     object_detection_model=model_yolo,
                                     pipeline=classifier)
```
- **Описание**: Функция извлекает теги из изображения, используя YOLOv8 для обнаружения объектов и transformers для классификации изображения методом нулевого шага.
- **Параметры**:
  - `image_path`: путь к изображению.
  - `object_detection_model`: загруженная модель YOLOv8.
  - `pipeline`: загруженная модель transformers/pipeline для классификации.
- **Выходные данные**:
  - `image_tags`: список тегов.

##### 3.2.2. Извлечение Тегов из Видео
```python
video_tags, list_cls = tags_extraction_complex(source_path=video_path,
                                               object_detection_model=model_yolo,
                                               pipeline=classifier,
                                               video_frame_rate=1)
```
- **Описание**: Функция извлекает теги из видео, используя YOLOv8 для обнаружения объектов и transformers для классификации изображения методом нулевого шага. Обработка кадров выполняется с заданной частотой кадров.
- **Параметры**:
  - `video_path`: путь к видеофайлу.
  - `object_detection_model`: загруженная модель YOLOv8.
  - `pipeline`: загруженная модель transformers/pipeline для классификации.
  - `video_frame_rate`: частота кадров видео (кадр/сек).

##### 3.2.3. Объединенная функция для извлечения тегов из изображения или видео
Функция `tags_extraction_complex` предоставляет удобный способ извлечения тегов из различных типов контента с использованием комбинации YOLOv8 для обнаружения объектов и трансформеров для классификации изображений. При использовании zero-shot image classification  для видео, для обеспечения баланса между количеством кадров и результативностью, теги извлекаются теги только из первого, среднего и последнего кадра.

```python
source_video_path = 'путь/к/вашему/видео.mp4'
video_tags, list_cls = tags_extraction_complex(source_path=source_video_path,
                                               object_detection_model=model_yolo,
                                               pipeline=classifier,
                                               video_frame_rate=1)
print('Извлеченные теги из видео: ', video_tags)
```

**- Описание:** 
	- Функция определяет тип контента (изображение или видео) на основе его расширения.
	- Если предоставлено видео:
		- функция извлекает кадры с заданной частотой и извлекает теги с использованием YOLOv8 для каждого кадра.
		- далее для видео формируется список из трех кадров: первого, среднего и последнего и для этих кадров выполняется классификация тегов с использованием трансформеров.
		- Результаты объединяются в список тегов и возвращаются вместе с кадрами для классификации.
	- Если предоставлено изображение то функция извлекает теги из изображения, используя YOLOv8 для обнаружения объектов и transformers для классификации изображения, далее результаты объединяются в список тегов, который возвращается на выходе из функции.
- **Параметры**:
	- `source_path`: Путь до единицы контента (изображения или видео).
	- `object_detection_model`: Загруженная дообученная модель YOLOv8 для обнаружения объектов.
	- `pipeline`: Загруженный pipeline Zero Shot Classification для классификации изображений.
	- `video_frame_rate`: Частота кадрирования видео (по умолчанию 1 кадр в секунду).
- - **Выходные данные**:
	- `image_tags`: список тегов для изображения
	-  `video_tags, list_cls` : список тегов и кадры для классификации для видео


### 4. Особенности работы
#### 4.1 Object Detection с YOLOv8
- Убедитесь, что необходимые модели и веса доступны по указанным путям.
- Настройте уровень уверенности (`confidence` переменная) в соответствии с желаемым порогом обнаружения объектов.

#### 4.2 ZeroShot classification
- Тщательно отредактируйте словарь классов (`classes` переменная) в соответствии с вашими конкретными потребностями классификации. 
- Точность классификации может зависеть от того, как формулируются метки. Информативное и точное описание меток может улучшить результаты классификации.
- модели ZeroShot Classification требуют значительных вычислительных ресурсов, особенно если они базируются на глубоком обучении и предоставляют высокую точность, поэтому при использовании трансформеров необходимо подключение GPU
-  словарь классов (`classes` переменная) можно самостоятельно редактировать для достижения полученных результатов.

### 5. Примечания
- Функционал кода для  экспорта изображений и тегов в файл Excel, включая сами теги, количество тегов и тип тега необходим для тестирования результатов, в дальнейшей работе он не понадобится (только при перенастройке результатов работы сети, также для тестирования результатов)
